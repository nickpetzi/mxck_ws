{"cells":[{"cell_type":"markdown","id":"bdb8453f","metadata":{"id":"bdb8453f"},"source":["# Lane Detection using OpenCV"]},{"cell_type":"code","execution_count":4,"id":"bff8f4ad","metadata":{"id":"bff8f4ad","executionInfo":{"status":"ok","timestamp":1668609919601,"user_tz":-60,"elapsed":743,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"outputs":[],"source":["%matplotlib inline\n","import cv2\n","import numpy as np\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from IPython.display import clear_output\n","import os\n","import json\n","import time\n","import yaml"]},{"cell_type":"markdown","source":["## Configuration"],"metadata":{"id":"g5HVluC8GegD"},"id":"g5HVluC8GegD"},{"cell_type":"code","source":["class Line():\n","\n","  def __init__(self):\n","\n","    ''' validation image '''\n","    ln_id = None # segmenation line id\n","    bd_id = None # segmenation border id\n","\n","    ''' set variables '''\n","    self.set_ln_vars()\n","\n","  def set_ln_rating(self):\n","    ''' set or reset rating variables '''\n","\n","    self.r_border = 0 # rating border\n","    self.r_iou = 0 # rating intersection over union\n","    self.r_len = 0 # rating length\n","    self.r_total = 0 # total rating\n","  \n","  def set_ln_vars(self):\n","    ''' set or rset variables '''\n","\n","    ''' polyfit '''\n","    self.fit = None # polyfit\n","    self.prevfit = None # previous polyfit\n","    self.polypix = None # x-y-coord polyfit\n","\n","    ''' gradient 1st order polyfit '''\n","    self.grad = None \n","\n","    ''' plotting '''\n","    self.winco = None # ((x1,y1),(x2,y2)) window coordinates\n","    self.winpx = None # pixel bordered by windows\n","\n","    ''' base '''\n","    self.xbase = None # start base of the line\n","\n","    ''' quality rating '''\n","    self.set_ln_rating()\n","\n","\n","def set_images(self):\n","  ''' set or reset images '''\n","\n","  self.im_input = None # input image\n","  self.im_canny = None # result canny edge detection\n","  self.im_range = None # result color range\n","  self.im_warped = None # birds eye view transformed\n","  self.im_bwarped = None # binaray warped\n","  self.im_hist = None # histogram\n","  self.im_polyfit = None # result polyfit search\n","  self.im_win = None # result sliding window search\n","  self.im_gt = None # ground trith visualization\n","  self.im_masked = None # engine hood removed\n","  self.im_prep = None # im_masked + croped\n","\n","def decl_variables(self):\n","\n","  ''' images '''\n","  set_images(self)\n","  self.im_val = None # validation image semantic map\n","  self.im_rating = None # quality rating visualization \n","  self.im_match = None # match between predicted and preprocessed line\n","  self.dyn_mask = None # dynamic mask from previous detection\n","\n","  ''' line '''\n","  self.ll = Line() # left line\n","  self.rl = Line() # right line\n","  self.lns = [self.ll, self.rl] # lines\n","\n","  ''' vehicle control '''\n","  self.prev_ofst_m = None # previous offset vehicle to center of the road\n","  self.ofst_m = None # offset vehicle to center of the road\n","\n","\n","def decl_config(self):\n","\n","  ''' clear all attributes '''\n","  self.__dict__ = {}\n","\n","  ''' image '''\n","  self.im_h = None # image height\n","  self.im_w = None # image width\n","  self.im_cx = None # image center x\n","  self.im_size = None # (width, height)\n","\n","  ''' camera '''\n","  self.cam_ofst_m = None # RGB camera offset in x from vehicle center [meters]\n","  self.cam_ofst_px = None\n","\n","  ''' road '''\n","  self.roadx_m = None # road width [meters]\n","  self.roadx_px = None # road width [pixels]\n","  self.roadx_tol_per = None # road with tolerance [%]\n","  self.roadx_tol_px = None # road with tolerance [pixels]\n","\n","  ''' line '''\n","  self.lnx_m = None # line width [meters]\n","  self.lnx_px = None # line width [pixels]\n","  self.lnx_tol_per = None # line width tolerance [%]\n","  self.lnx_tol_px = None # line width tolerance [pixels]\n","  self.half_roadx_px = None # road center to line center\n","  self.llx = None # left  line pos x [pixels]\n","  self.rlx = None # right line pos x [pixels]\n","  self.rlx_m = None # right  line pos x [meters]\n","  self.llx_m = None # left  line pos x [meters]\n","\n","  ''' quality rating '''\n","  self.w_border = None # weight border rating\n","  self.w_iou = None # weight iou rating\n","  self.w_len = None # weight length rating\n","\n","  self.rmin = None # min required rating\n","\n","  self.ln_pixmax = None # max pixel per line\n","\n","  self.road_det = False # road detected true/false\n","\n","  ''' sliding window search'''\n","  self.win_w = None # window width [pixel]\n","  self.win_h = None # window height [pixel]\n","  self.win_pixmax = None # max pixels found to recenter window\n","  self.win_pixmin = None # min pixels found to recenter window\n","  self.win_num = None # number of windows \n","\n","  ''' polyfit search '''\n","  self.poly_minpix = None # min pixel to calc polyfit\n","  self.nth_order = None # n-th order polyfit\n","  self.do_polysearch = None # perform polysearch true/false\n","\n","  ''' image preprocessing '''\n","  self.apply_canny = None # apply canny edge detection\n","  self.apply_range = None # apply hls color detection\n","  self.canny_tmax = None # canny edge detection max threshold\n","  self.canny_tmin = None # canny edge detection min threshold\n","  self.hls_tmax = None # (hue, saturation, lightness) min lightness\n","  self.hls_tmin = None # (hue, saturation, lightness) max lightness\n","  self.apply_dmask = None # apply dynamic mask\n","  self.prp_pxmax = None # minimun filtered out pixels\n","  self.prp_pxmin = None # maximum filtered out pixels\n","  self.canny_mask = None # remove unwanted edges resulting from transformation\n","  self.hood_mask = None # remove engine hood\n","\n","  ''' histogram '''\n","  self.hist_frac = None # calculate histogram for the lower fraction[%] of the image\n","  self.hist_y0 = None # calculate histogram for img[histo_y0:, :]\n","  self.hist_min = None # peak min pixels\n","\n","  ''' vehicle control '''\n","  self.kD = None\n","  self.kP = None\n","  self.steer_max = None # max. ackerman steering angle [deg]\n","  self.steer_min = None\n","\n","  ''' image transformation '''\n","  self.M = None # perspective transformation matrix\n","  self.Minv = None # inverse perspective transformation matrix\n","  self.m2px_x = None # conversion factors meters to pixel\n","  self.m2px_y = None\n","  self.px2m_x = None # conversion factors pixel to meters\n","  self.px2m_y = None\n","\n","  ''' groud truth viz '''\n","  self.lnx_mark = None # x coordinates road section marker\n","  self.lny_mark = None # y coordinates road section marker\n","\n","  ''' save config template '''\n","  self.tpl_config =  self.__dict__.copy() # template config\n","\n","\n","\n","def save_config(self, fpath):\n","  ''' Save the current config as yaml file '''\n","\n","  if fpath is None: return\n","\n","  config = self.tpl_config.copy() # blank config\n","  cur_config = self.__dict__ # current config\n","  \n","  for k in config.keys():\n","\n","    if not hasattr(self, k): continue # skip if not existant\n","\n","    val = getattr(self, k)\n","    if isinstance(val, np.ndarray): # numpy to list\n","      val = val.tolist()\n","\n","    elif isinstance(val, tuple): # tuple to list\n","      val = list(val)\n","\n","    config[k] = val\n","\n","  with open(fpath, 'w') as o:\n","    yaml.dump(config, o, default_flow_style = False)\n","\n","\n","\n","def load_config(self, fpath):\n","  ''' Load config from yaml file '''\n","\n","  if fpath is None: return\n","\n","  # read from yaml\n","  with open(fpath, 'r') as s:\n","    try: \n","      config = yaml.safe_load(s)\n","    except yaml.YAMLError as exc:\n","      print(exc)\n","\n","  # assign attributes\n","  for k, v in config.items():\n","\n","    if isinstance(v, list):\n","      v = np.array(v) # list to numpy\n","\n","    self.__dict__[k] = v\n","\n","\n","def show_config(self):\n","\n","  config = {} # blank config\n","            \n","  for k in self.tpl_config.keys():\n","    if not hasattr(self, k): continue\n","\n","    val = getattr(self, k)\n","    if isinstance(val, np.ndarray): # numpy to list\n","      val = val.tolist()\n","\n","    config[k] = val\n","\n","  print(json.dumps(config, indent=2))\n","\n"],"metadata":{"id":"hK3cqXGvAdm2","executionInfo":{"status":"ok","timestamp":1668616805345,"user_tz":-60,"elapsed":10,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"id":"hK3cqXGvAdm2","execution_count":173,"outputs":[]},{"cell_type":"markdown","source":["## Sample Data"],"metadata":{"id":"_IduVxxNHDYc"},"id":"_IduVxxNHDYc"},{"cell_type":"code","execution_count":174,"id":"575501e5","metadata":{"id":"575501e5","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"9381a07f-c2b7-45f0-aaae-7d14aac9a801","executionInfo":{"status":"ok","timestamp":1668616807561,"user_tz":-60,"elapsed":1148,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           fname  width  height  steering_angle  speed\n","0  frame0356.png    640     360          -0.010    0.3\n","1  frame0357.png    640     360          -0.010    0.3\n","2  frame0358.png    640     360          -0.009    0.3\n","3  frame0359.png    640     360          -0.010    0.3\n","4  frame0360.png    640     360           0.010    0.3"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fname</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>steering_angle</th>\n","      <th>speed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>frame0356.png</td>\n","      <td>640</td>\n","      <td>360</td>\n","      <td>-0.010</td>\n","      <td>0.3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>frame0357.png</td>\n","      <td>640</td>\n","      <td>360</td>\n","      <td>-0.010</td>\n","      <td>0.3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>frame0358.png</td>\n","      <td>640</td>\n","      <td>360</td>\n","      <td>-0.009</td>\n","      <td>0.3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>frame0359.png</td>\n","      <td>640</td>\n","      <td>360</td>\n","      <td>-0.010</td>\n","      <td>0.3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>frame0360.png</td>\n","      <td>640</td>\n","      <td>360</td>\n","      <td>0.010</td>\n","      <td>0.3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":174}],"source":["sample_dir = os.path.join(os.getcwd(), \"sample_data\")\n","im_dir = os.path.join(sample_dir, \"left_round_2022_10_08\")\n","summary_csv = csv_fpath = os.path.join(im_dir, \"summary.csv\")\n","\n","# read ground truth data\n","df = pd.read_csv(summary_csv)\n","df.sort_values(by=['fname'], inplace=True)\n","\n","# image for homography matrix and pixel to meters conversion factor\n","geo_fpath = os.path.join(sample_dir, 'calib_H_px2m.png')\n","geo_im = np.array(plt.imread(geo_fpath) * 255, dtype = np.uint8) \n","\n","# image sequence for testing\n","im_fpaths = [os.path.join(im_dir, f) for f in df['fname']]\n","images = [np.array(plt.imread(f) * 255, dtype = np.uint8) for f in im_fpaths]\n","\n","# select random images to test the prepocessing pipeline\n","rnd_int = np.random.choice(len(images), size = (10,), replace = False)\n","pro_images =  [images[i] for i in rnd_int]\n","\n","df.head()"]},{"cell_type":"markdown","source":["## Ground Truth Analysis"],"metadata":{"id":"xj8Ewq7SJqyd"},"id":"xj8Ewq7SJqyd"},{"cell_type":"code","source":["def plot_gt(self, im, gt_rad, pred_rad = None, ofst_px = None):\n","  ''' gt_rad: ground truth steering angle in rad\n","      pred_rad: predicted steering angle in degree\n","      ofst_px: offset vehicle to lane center in pixel\n","  '''\n","\n","  self.set_image(im)\n","  self.preprocess_image()\n","\n","\n","  rad = -gt_rad # steering [rad]\n","  deg = np.rad2deg(rad) # steering [deg]\n","\n","  if not pred_rad is None:\n","    pred_rad = -pred_rad # steering [rad]\n","    pred_deg = np.rad2deg(pred_rad)\n","\n","\n","  # define figure\n","  plt.clf() # clear figure\n","  fig = plt.figure(figsize = (20,7))\n","  ax = fig.add_subplot(111)\n","  ax.set_aspect('equal')\n","  ax.set_xlim(left=0, right=self.im_w)\n","  ax.set_ylim(top=0, bottom=self.axle_c[1] + 20)\n","\n","\n","  # plot image\n","  plt.imshow(self.im_warped)\n","  plt.grid()\n","\n","  # calculate steering angle in deg for left and right wheel\n","  l, r = get_ackermann_angles(self, deg)\n","\n","  # plot RIGHT wheel\n","  rtr = mpl.transforms.Affine2D().rotate_deg_around(self.cw_r[0], self.cw_r[1], r)  + ax.transData # rotation\n","  wr = plt.Rectangle(self.sw_r, self.xw, self.dw, fc='gray', ec='k', lw=2, transform=rtr) # rotate rectangle\n","  ax.add_patch(wr) # plot rotated rectangle \n","\n","  # plot LEFT wheel\n","  ltr = mpl.transforms.Affine2D().rotate_deg_around(self.cw_l[0], self.cw_l[1], l)  + ax.transData # rotation\n","  wl = plt.Rectangle(self.sw_l, self.xw, self.dw, fc='gray', ec='k', lw=2, transform=ltr) # rotate rectangle\n","  ax.add_patch(wl) # plot rotated rectangle \n","\n","  # plot fron AXLE\n","  plt.plot((self.cw_l[0], self.cw_r[0]), (self.cw_l[1], self.cw_r[1]),\n","           color = 'g', marker = 'o', markersize = 1)\n","\n","  # plot heading direction\n","  len_arrow = int((self.axle_c[1] - self.im_h) * 0.6)\n","  rx = int(np.sin(rad) * len_arrow)\n","  ry = int(np.cos(rad) * len_arrow)\n","\n","  plt.arrow(self.axle_c[0], self.axle_c[1], rx, -ry, color = 'g', head_width = 8, label = str(int(deg)) + '°')\n","\n","  if not pred_rad is None:\n","    # plot predicted heading direction\n","    rx = int(np.sin(pred_rad) * len_arrow)\n","    ry = int(np.cos(pred_rad) * len_arrow)\n","\n","    plt.arrow(self.axle_c[0], self.axle_c[1], rx, -ry, color = 'y', head_width = 8, label = str(int(pred_deg)) + '°')\n","\n","  # axes labeling in cm\n","  xt_px = np.array([self.llx, 0, self.rlx])\n","  xt_cm = np.array([self.llx_m, 0, self.rlx_m]) * 100\n","  plt.xticks(xt_px, [str(int(t)) + ' cm' for t in xt_cm])\n","\n","  yt_px = np.array([self.axle_c[1], self.im_h - 1])\n","  yt_px = np.append(yt_px, np.linspace(self.im_h, 0, 5)[1:])\n","  yt_cm = np.abs(np.array((yt_px - self.axle_c[1]) * self.px2m_y * 100, dtype = np.int16))\n","  plt.yticks(yt_px, [str(int(t)) + ' cm' for t in yt_cm])\n","\n","  plt.legend()\n","\n","  # plot line position marks\n","  ax.plot(self.lnx_mark, self.lny_mark, marker = '|', markersize=17)\n","\n","  # plot offset\n","  if not ofst_px is None:\n","    ax.plot(self.im_cx + ofst_px, self.lny_mark[0], marker = '|',\n","            markersize=17, markeredgewidth=2, color = 'r')\n","  \n","  # save as image\n","  temp_fname = 'temp.jpg'\n","  plt.savefig(temp_fname, bbox_inches='tight', pad_inches=.1)\n","  self.im_gt = plt.imread(temp_fname)\n","  os.remove(temp_fname)\n","  plt.clf() # clear figure\n","\n"],"metadata":{"id":"8OsdWSY4cjQb","executionInfo":{"status":"ok","timestamp":1668616807586,"user_tz":-60,"elapsed":15,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"id":"8OsdWSY4cjQb","execution_count":175,"outputs":[]},{"cell_type":"markdown","id":"2c002ba0","metadata":{"id":"2c002ba0"},"source":["## Calibration\n","\n","**Define Perspective transform matrix M and Pixel to Meter conversion factor**\n","The image coordinates are displayed at the bottom right of the diagram when the mouse hovers over the image. Use the zoom tool to make fine adjustment."]},{"cell_type":"code","execution_count":176,"id":"9ff125e0","metadata":{"id":"9ff125e0","executionInfo":{"status":"ok","timestamp":1668616808197,"user_tz":-60,"elapsed":16,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"outputs":[],"source":["def calib_geometry(self, geo_im):\n","  ''' geo_im: geomterie calibration image '''\n","\n","  self.prep_input(geo_im)\n","\n","  self.im_h, self.im_w, _ = self.im_prep.shape\n","  self.im_size = (self.im_w, self.im_h)\n","  self.im_cx = self.im_w//2\n","\n","\n","  # [(x1,y1),(x2,y2),(x3,y3),(x4,y3)] = [(top-left),(top-right),(bottom-right),(bottom-left)]\n","  y1 = y2 = 49 \n","  y3 = y4 = 110\n","\n","  x1 = 225\n","  x2 = 480\n","  x3 = 650\n","  x4 = 83\n","\n","  src = np.float32([[x1, y1], [x2, y2], [x3, y3], [x4, y4]])\n","\n","  y1_ = y2_ = 10\n","  y3_ = y4_ = 155\n","  x1_ = x4_ = (self.im_w - (y4_ - y1_)) // 2\n","  x2_ = x3_ = self.im_w - x1_\n","\n","  dst = np.float32([[x1_, y1_], [x2_, y2_], [x3_, y3_], [x4_, y4_]])\n","\n","  # Given src and dst points, calculate the perspective transform matrix\n","  self.M = cv2.getPerspectiveTransform(src, dst)\n","  # Return the resulting image and matrix\n","  self.Minv = cv2.getPerspectiveTransform(dst, src)\n","  # Warp the image using OpenCV warpPerspective()\n","  warped_im = cv2.warpPerspective(self.im_prep, self.M, self.im_size)\n","\n","  fig = plt.figure(figsize=(30, 20))\n","  fig.tight_layout()\n","\n","  '''Plot config image and src points'''\n","  plt.subplot(2,2,1) #nrows, ncols, index\n","  plt.imshow(self.im_prep)\n","  src = np.append(src, [src[0]], axis = 0) #repeat the first point to create a 'closed loop'\n","  plt.plot(src[:,0], src[:,1], c = 'r')\n","\n","  '''Plot warped image and dst points'''\n","  plt.subplot(2,2,2)\n","  plt.imshow(warped_im)\n","  dst = np.append(dst, [dst[0]], axis = 0)\n","  plt.plot(dst[:,0], dst[:,1], c = 'r')\n","\n","  '''Calculate conversion factors'''\n","\n","  x_m, y_m = 0.9, 0.9 # width in x[m], width in y[m]\n","  x_px, y_px = x2_ - x1_, y4_ - y1_ # width in x[pixel], width in y[pixel]\n","\n","  ''' Plot reference point \n","      Used to calculate the distance between the front axle and the projection '''\n","  self.xref = self.im_w // 2\n","  self.yref = y4_\n","\n","  # conversion factors\n","  self.m2px_x = float(x_px/x_m) # meter to pixel\n","  self.m2px_y = float(y_px/x_m)\n","  self.px2m_x = 1/self.m2px_x # pixel to meter\n","  self.px2m_y = 1/self.m2px_y\n","\n","\n","  '''Plot warped image and scale line'''\n","  plt.subplot(2,2,3)\n","  plt.imshow(warped_im)\n","  pts = np.array([[x1_, y1_], \n","                  [x2_, y2_],\n","                  [x3_, y3_],\n","                  [x4_, y4_],\n","                  [x1_, y1_]])\n","\n","  plt.plot(pts[:,0], pts[:,1], c = 'g')\n","\n","  plt.plot(self.xref, self.yref, marker = 'o', c = 'r') # plot reference pt\n","\n","  plt.show()"]},{"cell_type":"markdown","id":"03352666","metadata":{"id":"03352666"},"source":["## Image Preprocessing"]},{"cell_type":"code","execution_count":177,"id":"26fa503f","metadata":{"id":"26fa503f","executionInfo":{"status":"ok","timestamp":1668616808740,"user_tz":-60,"elapsed":8,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"outputs":[],"source":["def generate_hood_mask(self, im):\n","\n","  self.hood_mask = np.ones_like(im, dtype = np.uint8)\n","\n","  contour = np.array(\n","  [[45, 360],\n","  [85 , 345],\n","  [118, 338],\n","  [153, 332],\n","  [185, 332],\n","  [226, 335],\n","  [265, 309],\n","  [316, 313],\n","  [354, 310],\n","  [400, 308],\n","  [443, 310],\n","  [481, 317],\n","  [528, 314],\n","  [559, 324],\n","  [605, 320],\n","  [640, 322],\n","  [640, 360]], dtype = np.int32)\n","\n","  cv2.fillPoly(self.hood_mask, [contour], (0,0,0))\n","\n","def generate_canny_mask(self, im):\n","  ''' by the perspective transformation the image is brought into a\n","      trapezoid shape. to avoid that the left and right side of the\n","      trapezoid is recognized as an edge we remove it '''\n","\n","  plane = np.full_like(im, fill_value = 255, dtype = np.uint8)\n","  self.set_image(plane)\n","\n","  # Perspective transform image\n","  self.im_warped = cv2.warpPerspective(self.im_prep, self.M, self.im_size)\n","  self.apply_canny_thresh()\n","\n","  self.canny_mask = self.im_canny + 1\n","  self.canny_mask[self.canny_mask > 1] = 0\n","  \n","\n","def set_image(self, im):\n","  self.im_input = im\n","\n","  # crop image and remove engine hood\n","  self.prep_input()\n","\n","def prep_input(self, im = None):\n","  \n","  if im is None: im = self.im_input\n","\n","  # remove engine hood before perspective transform\n","  self.im_masked = np.multiply(im, self.hood_mask, dtype = np.uint8)\n","\n","  # crop image\n","  self.im_prep = self.im_masked[im.shape[0] // 2:, :, :]\n","\n","def apply_hls_thresh(self, im = None):\n","  if im is None: im = self.im_warped\n","\n","  # Convert to HLS color space and separate the S channel\n","  hls = cv2.cvtColor(im, cv2.COLOR_RGB2HLS)\n","  s_channel = hls[:,:,1]\n","\n","  # Creating image masked in S channel\n","  self.im_range = np.zeros_like(s_channel)\n","  self.im_range[(s_channel >= self.hls_tmin) & (s_channel <= self.hls_tmax)] = 1\n","  \n","\n","def apply_canny_thresh(self, im = None):\n","  if im is None: im = self.im_warped\n","\n","  # Convert to grayscale image and apply gaussian blur\n","  gray_im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n","  blur_im = cv2.GaussianBlur(gray_im, (5, 5), 0)\n","  \n","  # Apply canny edge detection\n","  self.im_canny = cv2.Canny(blur_im, self.canny_tmin, self.canny_tmax)\n","\n","  self.im_canny[self.im_canny > 0] = 1 # to binary\n","\n","  if not self.canny_mask is None:\n","    self.im_canny = np.multiply(self.im_canny, self.canny_mask)\n","\n","\n","def apply_mask(self):\n","\n","  # check if dyn_mask and im_bwarped exist\n","  if not (self.dyn_mask is None or self.im_bwarped is None):\n","    \n","    print('Applying mask...')\n","    \n","    # apply mask\n","    self.im_bwarped = np.multiply(self.im_bwarped, self.dyn_mask)\n","\n","\n","def preprocess_image(self):\n","  \n","  # Perspective transform image\n","  self.im_warped = cv2.warpPerspective(self.im_prep, self.M, self.im_size)\n","  \n","  # Colour thresholding in S channel\n","  if self.apply_range:\n","    self.apply_hls_thresh()\n","  \n","  # Edge detcetion with canny edge detection operator\n","  if self.apply_canny:\n","    self.apply_canny_thresh()\n","  \n","  # Combining both thresholds\n","  self.im_bwarped = self.im_canny.copy() if self.apply_canny else self.im_range.copy()\n","\n","  if self.apply_canny and self.apply_range:\n","    self.im_bwarped[self.im_range == 1] = 1\n","\n","  # Mask image\n","  if self.apply_dmask:\n","    # check if mask is reliable\n","    if (self.ll.r_total > self.rmin or self.rl.r_total > self.rmin):\n","      apply_mask(self)\n","    \n","  # Validate preprocessing\n","  '''\n","  nz = len(self.im_bwarped.nonzero()[0])\n","  print(nz)\n","  if nz > self.prp_pxmax or nz < self.prp_pxmin:\n","    self.road_det = False\n","    print('Preprocessing failed.')\n","  '''\n","\n","\n"]},{"cell_type":"markdown","id":"3da2bddb","metadata":{"id":"3da2bddb"},"source":["## Sliding Window Search"]},{"cell_type":"markdown","source":["### Histogram"],"metadata":{"id":"9aoPOwg89fIA"},"id":"9aoPOwg89fIA"},{"cell_type":"code","source":["def plot_canny_histogram(self, bins, hist):\n","\n","  clr = (255,0,0) # color\n","\n","  # Create an output image to draw on and  visualize the result\n","  self.im_hist = np.dstack((self.im_bwarped,\n","                            self.im_bwarped, self.im_bwarped)) * 255\n","\n","  # Visualize histogram\n","  plotx = np.repeat(bins, 2)[1:-1]\n","  ploty = np.repeat(hist[:,0], 2)\n","\n","  # Draw polyline on image\n","  line = np.asarray(tuple(zip(plotx, self.im_h - ploty)), np.int32)\n","  self.im_hist = cv2.polylines(self.im_hist, [line], False, clr, thickness=3)\n","\n","def get_canny_histogram(self, dev_mode = False):\n","\n","  n_bins = 21 # choose an odd number\n","  bins = np.linspace(start = 0, stop = self.im_w, num = 21).astype(int)\n","\n","  hist = np.empty(shape = (0, 2)).astype(int)\n","  for x1, x2 in zip(bins[:-1], bins[1:]):\n","    nx = self.im_bwarped[self.hist_y0:, x1:x2].nonzero()[0]\n","    cx = x1 + np.mean(nx).astype(int) if len(nx) > 0 else 0\n","    hist = np.append(hist, [[len(nx), cx]], axis=0) \n","\n","\n","  # plot histogram\n","  if dev_mode:\n","    plot_canny_histogram(self, bins, hist)\n","\n","\n","  # get histogram peaks\n","  l_peak  = np.max(hist[:n_bins//2, 0]) # peak size px\n","  r_peak = np.max(hist[n_bins//2:, 0])\n","\n","  lx_peak = hist[np.argmax(hist[:n_bins//2, 0]), 1]\n","  rx_peak = hist[n_bins//2 + np.argmax(hist[n_bins//2:, 0]), 1]\n","\n","  # detected road width \n","  det_roadx_px = rx_peak - lx_peak \n","\n","  # no valid peak (no line)\n","  if max(l_peak, r_peak) < self.hist_min:\n","    print(f'l_peak: {l_peak}, r_peak: {r_peak}, hist_min: {self.hist_min}')\n","    self.road_det = False\n","    return\n","\n","  # one valid peak (one line)\n","  if ((l_peak >= self.hist_min) ^ (r_peak >= self.hist_min)):\n","\n","    if l_peak >= r_peak: # keep max peak\n","      self.ll.xbase = lx_peak\n","    else:\n","      self.rl.xbase = rx_peak\n","\n","    return\n","\n","  # road width outside tolerance\n","  if abs(det_roadx_px - self.roadx_px) > self.roadx_tol_px:\n","\n","    if l_peak >= r_peak: # keep max peak\n","      self.ll.xbase = lx_peak\n","    else:\n","      self.rl.xbase = rx_peak\n","\n","    return\n","    \n","  # else two valid peaks (two lines)\n","  self.ll.xbase, self.rl.xbase = lx_peak, rx_peak\n","\n","print(rd.im_bwarped.shape)\n","rd.get_canny_histogram(dev_mode = True)\n","plt.imshow(rd.im_bwarped)\n","plt.plot([116, 176], [150, 150])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"uXsWElTi_l_S","executionInfo":{"status":"ok","timestamp":1668616809870,"user_tz":-60,"elapsed":90,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}},"outputId":"b4d0da0e-d01e-4304-c17e-c95f74f3e46d"},"id":"uXsWElTi_l_S","execution_count":178,"outputs":[{"output_type":"stream","name":"stdout","text":["(180, 640)\n"]},{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x2df11a70880>]"]},"metadata":{},"execution_count":178},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","execution_count":179,"id":"8f3fcd13","metadata":{"id":"8f3fcd13","executionInfo":{"status":"ok","timestamp":1668616809883,"user_tz":-60,"elapsed":13,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"outputs":[],"source":["def plot_histogram(self, hist):\n","\n","  clr = (255,0,0) # color\n","\n","  # Create an output image to draw on and  visualize the result\n","  self.im_hist = np.dstack((self.im_bwarped,\n","                            self.im_bwarped, self.im_bwarped)) * 255\n","\n","  # Visualize histogram\n","  plotx = np.linspace(0, self.im_w - 1, self.im_w)\n","\n","  # Draw polyline on image\n","  line = np.asarray(tuple(zip(plotx, self.im_h - hist)), np.int32)\n","  self.im_hist = cv2.polylines(self.im_hist, [line], False, clr, thickness=3)\n","\n","def get_histogram(self, dev_mode = False):\n","\n","  self.road_det = True\n","    \n","  self.ll.xbase, self.rl.xbase = None, None # reset\n","\n","  # calculate histogram\n","  hist = np.sum(self.im_bwarped[self.hist_y0:,:], axis=0) \n","\n","  # plot histogram\n","  if dev_mode:\n","    plot_histogram(self, hist)\n","      \n","  # get histogram peaks\n","  l_peak  = np.max(hist[:self.im_cx]) # peak size px\n","  r_peak = np.max(hist[self.im_cx:])\n","\n","  lx_peak  = np.argmax(hist[:self.im_cx])\n","  rx_peak = np.argmax(hist[self.im_cx:]) + self.im_cx\n","\n","  # detected road width \n","  det_roadx_px = rx_peak - lx_peak \n","  \n","  # no valid peak (no line)\n","  if max(l_peak, r_peak) < self.hist_min:\n","    print(f'l_peak: {l_peak}, r_peak: {r_peak}, hist_min: {self.hist_min}')\n","    self.road_det = False\n","    return\n","\n","  # one valid peak (one line)\n","  if ((l_peak >= self.hist_min) ^ (r_peak >= self.hist_min)):\n","\n","    if l_peak >= r_peak: # keep max peak\n","      self.ll.xbase = lx_peak\n","    else:\n","      self.rl.xbase = rx_peak\n","\n","    return\n","\n","  # road width outside tolerance\n","  if abs(det_roadx_px - self.roadx_px) > self.roadx_tol_px:\n","\n","    if l_peak >= r_peak: # keep max peak\n","      self.ll.xbase = lx_peak\n","    else:\n","      self.rl.xbase = rx_peak\n","\n","    return\n","    \n","  # else two valid peaks (two lines)\n","  self.ll.xbase, self.rl.xbase = lx_peak, rx_peak"]},{"cell_type":"markdown","source":["### Plot Window Search Result"],"metadata":{"id":"DvVizpCm9xkG"},"id":"DvVizpCm9xkG"},{"cell_type":"code","source":["def plot_window_search(self):\n","\n","  # create an output image to draw on and  visualize the result\n","  self.im_win = np.dstack((self.im_bwarped,\n","                            self.im_bwarped, self.im_bwarped)) * 255\n","  \n","  win_clr = (0,255,0) # window color\n","  ln_clr = (0,0,255) # line color\n","  px_clr = (255, 0, 0)\n","\n","  for ln in [self.ll, self.rl]:\n","\n","    if ln.fit is None: continue\n","\n","    # color pixels\n","    indices = (ln.winpx[:,1], ln.winpx[:,0])\n","    rd.im_win[indices] = px_clr\n","\n","    # Draw the windows on the visualization image\n","    for (p1, p2) in ln.winco:\n","      cv2.rectangle(self.im_win, p1, p2, win_clr, 2)\n","        \n","    # generate x and y values for plotting\n","    ymin = ln.winpx[:,1].min()\n","    ymax = ln.winpx[:,1].max()\n","    yrange = ymax - ymin\n","\n","    ploty = np.linspace(ymin, ymax, yrange)\n","        \n","    line_fitx = np.polyval(ln.fit, ploty)\n","\n","    # draw polyline on image\n","    line = np.asarray(tuple(zip(line_fitx, ploty)), np.int32)\n","    cv2.polylines(self.im_win, [line], False, ln_clr, thickness=3)"],"metadata":{"id":"kCHEzQxu96G5","executionInfo":{"status":"ok","timestamp":1668616810443,"user_tz":-60,"elapsed":8,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"id":"kCHEzQxu96G5","execution_count":180,"outputs":[]},{"cell_type":"markdown","source":["### Sliding Window"],"metadata":{"id":"VpzbVdSM97n_"},"id":"VpzbVdSM97n_"},{"cell_type":"code","execution_count":181,"id":"f3c058d8","metadata":{"id":"f3c058d8","executionInfo":{"status":"ok","timestamp":1668616811359,"user_tz":-60,"elapsed":11,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"outputs":[],"source":["def window_search(self, ln, dev_mode = False):\n","\n","  # skip if no line base found\n","  if ln.xbase is None:\n","    ln.fit, ln.grad = None, None\n","    return \n","\n","  # all x- and y-coordinates\n","  all_x = all_y = []\n","  \n","  # initial window coordinates (x1, y1), (x2, y2) := (top-left),(bottom-right)\n","  pred_cx = ln.xbase # initial window center pos in x\n","  prev_cx = None # previous window center pos in x\n","  y2 = self.im_h\n","  y1 = y2 - self.win_h\n","  x1 = pred_cx - self.win_w // 2\n","  x2 = pred_cx + self.win_w // 2\n","\n","  # clip window to image borders\n","  x1, x2 = np.clip([x1, x2], 0, self.im_w)\n","  y1, y2 = np.clip([y1, y2], 0, self.im_h)\n","\n","  dy = []\n","\n","  # step through the windows one by one\n","  for n in range(self.win_num):\n","      \n","    # nonzero x-y-coordinates\n","    y, x = self.im_bwarped[y1:y2, x1:x2].nonzero()\n","      \n","    # break if window not valid\n","    if len(x) > self.win_pixmax or len(x) < self.win_pixmin:\n","      print(f'Win Search stopped: len x: {len(x)}, win_pixmin: {self.win_pixmin}')\n","      break\n","    \n","    # shift from window coordinates to image coordinates\n","    y += y1\n","    x += x1\n","    \n","    # all pixels\n","    all_x = [*all_x, *x]\n","    all_y = [*all_y, *y]\n","\n","    if dev_mode:\n","\n","      # store pixels\n","      xy = np.stack((x,y), axis = 1)\n","      ln.winpx = xy if ln.winpx is None else np.concatenate((ln.winpx, xy), axis = 0)\n","\n","      # store window\n","      if ln.winco is None: ln.winco = [[(x1,y1), (x2,y2)]]\n","      else: ln.winco.append([(x1,y1), (x2,y2)])\n","\n","\n","    # calc next window position\n","    updated_cx = int(np.mean(x))\n","    updated_cy = int(np.mean(y))\n","\n","    '''\n","    in sharp curves, the camera only sees the outer line\n","    if there is only one line visible (single_line:=True) we calculate the gradient m \n","    if m < 0 -> right curve -> camera only sees left line\n","    if m > 0 -> left curve -> camera only sees right line\n","    '''\n","\n","    if prev_cx is None:\n","      m = np.polyfit(x, y, 1)[0]\n","      dx = 0 # -np.sign(m) * np.ptp(x)\n","    else:\n","      dx = updated_cx - prev_cx\n","\n","\n","    dy = np.ptp(y) # prediction along vector in y\n","\n","    pred_cx = updated_cx + int(dx) # prediction along vector in x\n","    prev_cx = updated_cx # previous\n","\n","\n","    # update window position\n","    y2 -= dy\n","    y1 -= dy\n","    x1 = pred_cx - self.win_w // 2\n","    x2 = pred_cx + self.win_w // 2\n","      \n","    # clip window to image borders\n","    x1, x2 = np.clip([x1, x2], 0, self.im_w)\n","    y1, y2 = np.clip([y1, y2], 0, self.im_h)\n","\n","  if len(all_x) > self.win_pixmin:\n","    # fit a 2nd order polynomial\n","    ln.fit = np.polyfit(all_y, all_x, 2)\n","\n","    # fit a 1st order polynomial \n","    ln.grad = np.polyfit(all_x, all_y, 1)[0] # x y switched\n","\n","  else:\n","    ln.fit, ln.grad = None, None\n","\n","\n","\n","def run_window_search(self, dev_mode = False):\n","\n","  self.road_det = True\n","\n","  # clear previous results\n","  for ln in self.lns:\n","    ln.set_ln_vars()\n","\n","  # get window base position\n","  if self.apply_canny and self.apply_range:\n","    self.get_histogram(dev_mode)\n","  elif self.apply_canny:\n","    self.get_canny_histogram(dev_mode)\n","\n","  if not self.road_det:\n","    print('No valid starting point found in histogram.')\n","    return\n","\n","  # run window search\n","  for ln in [self.ll, self.rl]:\n","    window_search(self, ln, dev_mode)\n","  \n","  if (self.ll.fit is None and self.rl.fit is None):\n","    self.road_det = False\n","  \n","  if self.road_det and dev_mode:\n","    self.plot_window_search()\n","\n","\n"]},{"cell_type":"markdown","id":"4f88e113","metadata":{"id":"4f88e113"},"source":["## Validate Lane Update"]},{"cell_type":"markdown","source":["### Generate Validation Image"],"metadata":{"id":"mPZ8HqAB2Y7e"},"id":"mPZ8HqAB2Y7e"},{"cell_type":"code","execution_count":183,"id":"9603ac03","metadata":{"id":"9603ac03","executionInfo":{"status":"ok","timestamp":1668616814454,"user_tz":-60,"elapsed":6,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"outputs":[],"source":["def get_validation_image(self):\n","    ''' \n","    generates semantic map\n","    background (0), left_line(1), left_line_border(2), right_line(3), right_line_border(4)\n","    '''\n","\n","    # Generate a validation image\n","    im_val = np.zeros((self.im_h, self.im_w, 3), dtype = np.uint8)\n","\n","\n","    for ln in self.lns:\n","\n","      if ln.fit is None:\n","        continue\n","\n","      # Generate x and y values for plotting\n","      ploty = np.linspace(0, self.im_h, self.im_h)\n","\n","      line_fitx = np.polyval(ln.fit, ploty)\n","      # Draw polyline on image\n","      line = np.asarray(tuple(zip(line_fitx, ploty)), np.int32)\n","      # Plot border\n","      cv2.polylines(im_val, [line], False, (0, ln.bd_id, 0), thickness=self.lnx_tol_px)\n","      # Plot ideal lane line\n","      cv2.polylines(im_val, [line], False, (0, ln.ln_id, 0), thickness=self.lnx_px)\n","\n","    self.im_val = np.max(im_val, axis = -1)\n","    \n","\n","def get_dynamic_mask(self):\n","\n","  # mask out background in preprocessing\n","  self.dyn_mask = np.zeros_like(self.im_val)\n","\n","  for ln in self.lns:\n","\n","    if ln.r_total > self.rmin:\n","      self.dyn_mask[(self.im_val == ln.bd_id) | (self.im_val == ln.ln_id)] = 1\n","\n","def plot_quality_rating(self):\n","\n","    self.im_rating = self.im_match + self.im_val\n","    self.im_rating += self.im_bwarped\n"]},{"cell_type":"markdown","source":["### Calculate Quality Rating"],"metadata":{"id":"jWKffIcf2ibz"},"id":"jWKffIcf2ibz"},{"cell_type":"code","source":["def validate_lane_update(self, dev_mode = False):    \n","  \n","  for ln in self.lns:\n","    ln.set_ln_rating () # rest rating\n","\n","  # loginfo\n","  msg = \"r_iou x r_len x r_border = r_total \\n\" \n","  tpl = \"{}:  {:0.2f} x {:0.2f} x {:0.2f} = {:0.2f} \\n\"\n","\n","  # get validation image\n","  self.get_validation_image()\n","  \n","  self.im_match = np.multiply(self.im_bwarped, self.im_val)\n","\n","  for s, ln in zip(['Left', 'Right'], self.lns):\n","    \n","    if ln.fit is None: continue\n","\n","    ln_px = (self.im_val == ln.ln_id).sum() # total line pixels\n","    bd_px = (self.im_val == ln.bd_id).sum() # total border pixels\n","\n","    ln_match = (self.im_match == ln.ln_id).sum() # matching line pixels\n","    bd_match = (self.im_match == ln.bd_id).sum() # matching border pixels\n","\n","    # line matching factor := 1.0\n","    # if predicted line identical with filtered line\n","    ln.r_iou = ln_match /ln_px if ln_px != 0 else 0\n","\n","    # border matching factor := 1.0 \n","    # if no artifacts in predicted border\n","    ln.r_border = 1 - (bd_match/bd_px) if bd_px != 0 else 0\n","\n","\n","    # length factor := 1.0 \n","    # if number of pixels > number of pixel in a straight line\n","    ln.r_len = np.clip(ln_match / self.ln_pixmax, 0, 1)\n","  \n","    # weights\n","    ln.r_total =  (self.w_iou * ln.r_iou + self.w_len * ln.r_len + \\\n","                   self.w_border * ln.r_border)\n","    \n","    # loginfo\n","    msg = msg + tpl.format(s, ln.r_iou, ln.r_len, ln.r_border, ln.r_total)\n","\n","  # check results\n","  if (self.ll.r_total < self.rmin and self.rl.r_total < self.rmin):\n","    self.road_det = False\n","    self.rl.set_ln_vars() # reset lines\n","    self.ll.set_ln_vars()\n","    return\n","  \n","  for ln in self.lns:\n","    if ln.r_total < self.rmin:\n","      self.im_val[(self.im_val == ln.ln_id) | (self.im_val == ln.bd_id)] = 0\n","      ln.set_ln_vars() # reset \n","\n","\n","\n","  if dev_mode:\n","    print(msg, dev_mode)\n","    self.plot_quality_rating()\n"],"metadata":{"id":"TkG1iziy2ix8","executionInfo":{"status":"ok","timestamp":1668616814472,"user_tz":-60,"elapsed":12,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"id":"TkG1iziy2ix8","execution_count":184,"outputs":[]},{"cell_type":"markdown","source":["## Polyfit Search"],"metadata":{"id":"O1uF6mp5iC0R"},"id":"O1uF6mp5iC0R"},{"cell_type":"code","source":["def plot_polysearch(self):\n","\n","  # Create an output image to draw on and  visualize the result\n","  self.im_polyfit = np.dstack((self.im_bwarped, self.im_bwarped,\n","                            self.im_bwarped)) * 255\n","  \n","  ln_clr = (0,0,255) # line color\n","\n","  for ln in self.lns:\n","\n","    if (ln.polypix is None or ln.fit is None): continue\n","\n","    # generate x and y values for plotting\n","    ymin = ln.polypix[:,1].min()\n","    ymax = ln.polypix[:,1].max()\n","    yrange = ymax - ymin\n","\n","    ploty = np.linspace(ymin, ymax, yrange)\n","\n","    line_fitx = np.polyval(ln.fit, ploty)\n","\n","    # Draw polyline on image\n","    line = np.asarray(tuple(zip(line_fitx, ploty)), np.int32)\n","    cv2.polylines(self.im_polyfit, [line], False, ln_clr, thickness=3)"],"metadata":{"id":"FL5aDUCyh4CV","executionInfo":{"status":"ok","timestamp":1668616815079,"user_tz":-60,"elapsed":4,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"id":"FL5aDUCyh4CV","execution_count":185,"outputs":[]},{"cell_type":"code","execution_count":186,"id":"b792e1e7","metadata":{"id":"b792e1e7","executionInfo":{"status":"ok","timestamp":1668616815096,"user_tz":-60,"elapsed":11,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"outputs":[],"source":["def polyfit_search(self, dev_mode=False):\n","    \n","    tmp_im = self.im_bwarped * self.im_val\n","    \n","    for ln in self.lns:\n","\n","        if ln.fit is None: continue\n","        \n","        all_y, all_x =  np.where((tmp_im == ln.ln_id) | (tmp_im == ln.bd_id))\n","\n","        if len(all_x) < self.poly_minpix: continue\n","        \n","        # weight polyfit (1/x)\n","        w = np.zeros_like(all_y, dtype = np.float16) \n","\n","        l = np.linspace(0, all_y.size, 5, dtype = np.int16)\n","\n","        for i in range(0, 4):\n","          w[l[i]:l[i+1]] = 1/(5-i)\n","\n","        # Fit a second order polynomial to each\n","        ln.fit = np.polyfit(all_y, all_x, self.nth_order, w = w)\n","\n","        # Fit a first order polynomial and save gradient\n","        ln.grad = np.polyfit(all_x, all_y, 1)[0]\n","\n","        # store pixels\n","        if dev_mode:\n","          ln.polypix = np.stack((all_x, all_y), axis = 1)\n","\n","    if (self.ll.fit is None and self.rl.fit is None):\n","      self.road_det = False\n","\n","    if dev_mode and self.road_det:\n","      plot_polysearch(self)"]},{"cell_type":"markdown","id":"a3e8c6b9","metadata":{"id":"a3e8c6b9"},"source":["## Lane Line Detection Pipeline"]},{"cell_type":"code","source":["def run_road_detection_(self, im, dev_mode = False):\n","  '''   road_det is set True at beginning of window search\n","        and returned as false if window search failes\n","\n","        road_det has to be true at beginning of polyfit search\n","        and returned as false if polyfit search failes\n","\n","  '''\n","  pass\n"],"metadata":{"id":"bGb1gWNS0izG","executionInfo":{"status":"ok","timestamp":1668616896717,"user_tz":-60,"elapsed":3,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"id":"bGb1gWNS0izG","execution_count":195,"outputs":[]},{"cell_type":"markdown","source":["## Controling"],"metadata":{"id":"7Mojo7eywZOp"},"id":"7Mojo7eywZOp"},{"cell_type":"code","execution_count":188,"id":"46395078","metadata":{"id":"46395078","executionInfo":{"status":"ok","timestamp":1668616816989,"user_tz":-60,"elapsed":5,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"outputs":[],"source":["def calc_steering_angle(self, dev_mode = False):\n","    \n","    if  self.ofst_m is not None:\n","         self.prev_ofst_m = self.ofst_m\n","    \n","    #left\n","    if self.ll.r_total >= self.rl.r_total:\n","        road_cx = np.polyval(self.ll.fit, self.im_h) + self.half_roadx_px\n","        theta = int(np.rad2deg(np.arctan(self.ll.grad)))\n","    \n","    # right\n","    else: \n","        road_cx = np.polyval(self.rl.fit, self.im_h) - self.half_roadx_px\n","        theta = int(np.rad2deg(np.arctan(self.rl.grad)))\n","    \n","    if theta <= 0: \n","        theta += 90\n","    else:\n","        theta -= 90\n","    \n","    ofst_px = self.im_cx - road_cx # offset to right (-) offset to left (+)\n","    self.ofst_m = ofst_px * self.px2m_x\n","    \n","    # PD controller\n","    # e.g. -0.2 m (offset to the right) * 110 (kP) = - 22° steering to the left\n","    p_steer = self.ofst_m * self.kP \n","\n","    # e.g. -0.1 m (movement to the right) * 50 (kD) = - 5° additional steering to the left\n","    if  self.prev_ofst_m is not None:\n","        d_steer = (self.prev_ofst_m - self.ofst_m) * self.kD\n","    else:\n","        d_steer = 0\n","\n","    steer = d_steer + p_steer # steering angle\n","    \n","    steer = np.clip(steer, self.steer_min, self.steer_max)\n","    \n","    if dev_mode:\n","        print(f\"Offset {int(self.ofst_m * 100)} cm, Steering angle {int(steer)}°, Gradient {int(theta)}°\")\n","        "]},{"cell_type":"code","source":["def get_ackermann_angles(self, deg = None):\n","  ''' calculate left and right steering angle in deg from\n","      inner steering angle\n","      see: https://www.xarg.org/book/kinematics/ackerman-steering/ '''\n","  \n","  rad = np.deg2rad(deg)\n","  l = np.rad2deg(np.arctan((2 * self.wb_m * np.sin(rad)) /\n","                           (2 * self.wb_m * np.cos(rad) +\n","                            self.xt_m * np.sin(rad))))\n","\n","  r = np.rad2deg(np.arctan((2 * self.wb_m * np.sin(rad)) /\n","                           (2 * self.wb_m * np.cos(rad) -\n","                            self.xt_m * np.sin(rad))))\n","  \n","  return l, r"],"metadata":{"id":"hjS1qNoMNPOu","executionInfo":{"status":"ok","timestamp":1668616817005,"user_tz":-60,"elapsed":10,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"id":"hjS1qNoMNPOu","execution_count":189,"outputs":[]},{"cell_type":"markdown","source":["## Test Pipeline"],"metadata":{"id":"Jf2oEyZtVvuc"},"id":"Jf2oEyZtVvuc"},{"cell_type":"markdown","source":["### Setup"],"metadata":{"id":"0ZhTzVKRIE0k"},"id":"0ZhTzVKRIE0k"},{"cell_type":"code","source":["class RoadDetection():\n","  def __init__(self, fpath = None):\n","    decl_config(self)\n","    decl_variables(self)\n","    #load_config(self, fpath)\n","    show_config(self)\n","    #save_config(self, fpath)\n","\n","  def generate_hood_mask(self, im):\n","    generate_hood_mask(self, im)\n","\n","  def generate_canny_mask(self, im):\n","    generate_canny_mask(self, im)\n","\n","  def prep_input(self, im = None):\n","    prep_input(self, im)\n","\n","  def calib_geometry(self, geo_im):\n","    calib_geometry(self, geo_im)\n","\n","  def decl_config(self):\n","    decl_config(self)\n","\n","  def decl_variables(self):\n","    decl_variables(self)\n","\n","  def load_config(self, fpath):\n","    load_config(self, fpath)\n","\n","  def show_config(self):\n","    show_config(self)\n","\n","  def save_config(self, fpath):\n","    save_config(self, fpath)\n","\n","  def set_image(self, im):\n","    set_image(self, im)\n","\n","  def preprocess_image(self):\n","    preprocess_image(self)\n","\n","  def apply_canny_thresh(self, im = None):\n","    apply_canny_thresh(self, im)\n","\n","  def apply_hls_thresh(self, im = None):\n","    apply_hls_thresh(self, im)\n","\n","  def get_histogram(self, dev_mode = False):\n","    get_histogram(self, dev_mode)\n","  \n","  def get_canny_histogram(self, dev_mode = False):\n","    get_canny_histogram(self, dev_mode)\n","\n","  def window_search(self, im, dev_mode = False):\n","    window_search(self, im, dev_mode)\n","\n","  def run_window_search(self, dev_mode = False):\n","    run_window_search(self, dev_mode)\n","  \n","  def plot_window_search(self):\n","    plot_window_search(self)\n","  \n","  def get_validation_image(self):\n","    get_validation_image(self)\n","  \n","  def get_dynamic_mask(self):\n","    get_dynamic_mask(self)\n","  \n","  def validate_lane_update(self, dev_mode = False):\n","    validate_lane_update(self, dev_mode)\n","  \n","  def plot_quality_rating(self):\n","    plot_quality_rating(self)\n","  \n","  def polyfit_search(self, dev_mode = False):\n","    polyfit_search(self, dev_mode)\n","\n","  def plot_polysearch(self):\n","    plot_polysearch(self)\n","\n","  def run_road_detection(self, im, dev_mode = False):\n","    run_road_detection(self, im, dev_mode)\n","  \n","  def set_images(self):\n","    set_images(self)\n","  \n","  def calc_steering_angle(self, dev_mode = False):\n","    calc_steering_angle(self, dev_mode)\n","  \n","  def visualize_gt(self, gt_deg, pred_deg = None, ofst_px = None):\n","    visualize_gt(self, gt_deg, pred_deg, ofst_px)\n","  \n","  def plot_gt(self, im, gt_rad, pred_rad = None, ofst_px = None):\n","    plot_gt(self, im, gt_rad, pred_rad, ofst_px)\n","\n","fpath = 'test_config.yaml'\n","\n","rd = RoadDetection(fpath)\n","rd.generate_hood_mask(geo_im)\n","rd.calib_geometry(geo_im)\n","rd.generate_canny_mask(geo_im)\n","clear_output()\n"],"metadata":{"id":"MK3EgVmzE70j","executionInfo":{"status":"ok","timestamp":1668616818663,"user_tz":-60,"elapsed":386,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"id":"MK3EgVmzE70j","execution_count":190,"outputs":[]},{"cell_type":"code","source":["''' wheels '''\n","rd.dw_m = 0.097 # wheel diameter [m]\n","rd.xw_m = 0.04 # wheel width [m]\n","rd.xt_m = 0.27 # track width [m]\n","rd.wb_m = 0.36 # wheelbase [m]\n","rd.dw = int(rd.dw_m * rd.m2px_x) # wheel diameter [pixel]\n","rd.xw = int(rd.xw_m * rd.m2px_x) # wheel width [pixel]\n","rd.xt = int(rd.xt_m * rd.m2px_x) # track width [pixel]\n","rd.wb = int(rd.wb_m * rd.m2px_x) # wheelbase [pixel]\n","\n","''' camera '''\n","rd.cam_ofst_m = -32.5e-3 # RealSense D435i -32.5 mm offset in x\n","rd.cam_ofst_px = int(rd.cam_ofst_m * rd.m2px_x)\n","\n","''' road geometry '''\n","rd.lnx_m = 0.05\n","rd.roadx_m = 0.75\n","rd.lnx_px = int(rd.lnx_m * rd.m2px_x)\n","rd.roadx_px = int(rd.roadx_m * rd.m2px_x)\n","rd.roadx_tol_per = 0.2\n","rd.roadx_tol_px = rd.roadx_px * rd.roadx_tol_per\n","rd.rlx_m =  (rd.roadx_m + rd.lnx_m) / 2 # right  line pos x [meters]\n","rd.llx_m =  -rd.rlx_m # left  line pos x [meters]\n","rd.rlx = int(rd.im_cx + rd.rlx_m * rd.m2px_x) # right line pos x\n","rd.llx = int(rd.im_cx + rd.llx_m * rd.m2px_x) # left  line pos x\n","\n","''' config preprocessing '''\n","rd.apply_range = False\n","rd.apply_canny = True\n","rd.hls_tmin = 90 # minimum lightness\n","rd.hls_tmax = 255 \n","rd.canny_tmin = 70\n","rd.canny_tmax = 255\n","rd.apply_dmask = False\n","rd.prp_pxmax = rd.lnx_px * rd.im_h * 4\n","rd.prp_pxmin = rd.lnx_px * rd.im_h // 4\n","\n","''' config window '''\n"," # ratio between fill and contour only ~ 5\n","rd.hist_frac = 0.1\n","rd.hist_y0 = int(rd.im_h * (1.0 - rd.hist_frac))\n","rd.hist_min = 5\n","rd.win_num = 8 \n","rd.win_w = 60\n","rd.win_h = rd.im_h // rd.win_num\n","rd.win_pixmin = rd.lnx_px * rd.win_w // 5 // 4\n","rd.win_pixmax = rd.lnx_px * rd.win_w \n","\n","''' validation '''\n","rd.ll.ln_id = 1 # segmenation line id\n","rd.ll.bd_id = 2 # segmenation border id\n","rd.rl.ln_id = 3\n","rd.rl.bd_id = 4\n","\n","rd.w_border = 0.2 # weight border rating\n","rd.w_iou = 0.6 # weight iou rating\n","rd.w_len = 0.2 # weight length rating\n","rd.rmin = 0.0 # 0.05 # min required rating\n","\n","rd.lnx_tol_per = 3.0\n","rd.lnx_tol_px = int(rd.lnx_px * rd.lnx_tol_per)\n","\n","rd.ln_pixmax = rd.im_h * rd.lnx_px\n","\n","''' polyfit search '''\n","rd.poly_minpix = (rd.lnx_px * rd.im_h) // 8 // 5\n","rd.nth_order = 2\n","rd.do_polysearch = True\n","\n","''' control '''\n","rd.half_roadx_px = (rd.roadx_px + rd.lnx_px) // 2\n","rd.kD = 110\n","rd.kP = 50\n","rd.steer_max =  30 \n","rd.steer_min = -30\n","\n","''' groud truth viz '''\n","x1 = rd.im_cx - rd.half_roadx_px - rd.lnx_tol_px // 2\n","x2 = rd.im_cx - rd.half_roadx_px + rd.lnx_tol_px // 2\n","x3 = rd.im_cx\n","x4 = rd.im_cx + rd.half_roadx_px - rd.lnx_tol_px // 2\n","x5 = rd.im_cx + rd.half_roadx_px + rd.lnx_tol_px // 2\n","y  = rd.im_h + 10\n","\n","rd.lnx_mark = np.array((x1, x2, x3, x4, x5)) + rd.cam_ofst_px\n","rd.lny_mark = np.repeat(y, 5)\n","\n","''' blindspot'''\n","# sw:= starting point (top left corner) l/r wheel\n","# cw:= center l/r wheel\n","\n","rd.xref_ofst_m = 0.0 # offset reference point to front axle [m]\n","rd.yref_ofst_m = 0.55\n","\n","rd.xref_ofst = int(rd.xref_ofst_m * rd.m2px_x)\n","rd.yref_ofst = int(rd.yref_ofst_m * rd.m2px_x)\n","\n","xs_l = rd.xref - (rd.xt + rd.xw) // 2 + rd.cam_ofst_px\n","xs_r = rd.xref + (rd.xt - rd.xw) // 2 + rd.cam_ofst_px\n","\n","ys_l = ys_r = rd.yref + rd.yref_ofst \n","\n","rd.sw_l = (xs_l, ys_l) # starting point\n","rd.sw_r = (xs_r, ys_r)\n","\n","rd.cw_l = (xs_l + rd.xw // 2, ys_l + rd.dw // 2) # center\n","rd.cw_r = (xs_r + rd.xw // 2, ys_r + rd.dw // 2) \n","\n","rd.axle_c = (rd.xref + rd.xref_ofst + rd.cam_ofst_px, rd.cw_l[1]) # center front axle\n"],"metadata":{"id":"WNDFvedOZ890","executionInfo":{"status":"ok","timestamp":1668616818680,"user_tz":-60,"elapsed":7,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"id":"WNDFvedOZ890","execution_count":191,"outputs":[]},{"cell_type":"markdown","source":["## Visualize Results"],"metadata":{"id":"3tiw1Vx-IBR9"},"id":"3tiw1Vx-IBR9"},{"cell_type":"code","source":["''' Test Pipeline '''\n","nrows = 2\n","ncols = 4\n","fsize = (4 * ncols, 2 * nrows)\n","\n","def initial_step(dev_mode = False):\n","\n","  rd.apply_canny, rd.apply_range, apply_dmask = True, False, False\n","\n","  rd.preprocess_image()\n","\n","  rd.run_window_search(dev_mode)\n","\n","  rd.validate_lane_update()\n","\n","  rd.get_dynamic_mask()\n","\n","rd.apply_dmask = False\n","rd.road_det = False\n","\n","for i, (fname, rad) in enumerate(zip(df['fname'], df['steering_angle'])):\n","\n","  if i == 60: break\n","\n","  # setup plot\n","  fig, ax = plt.subplots(nrows, ncols, figsize = fsize)\n","  fig.tight_layout()\n","\n","  # load image\n","  fpath = os.path.join(im_dir, fname)\n","  im = np.array(cv2.imread(fpath))\n","  rd.set_image(im)\n","\n","  # preprocessing\n","  rd.apply_canny, rd.apply_range, rd.apply_dmask = True, False, False\n","  rd.preprocess_image()\n","\n","  # run sliding window\n","  rd.run_window_search(dev_mode = True)\n","\n","  ax[0,0].imshow(rd.im_prep)\n","  ax[0,1].imshow(rd.im_bwarped, cmap = 'gray')\n","  if rd.road_det:\n","    ax[0,2].imshow(rd.im_win)\n","\n","    rd.validate_lane_update(dev_mode = True)\n","    rd.get_dynamic_mask()\n","\n","\n","    ax[0,3].imshow(rd.im_val)\n","\n","    rd.apply_canny, rd.apply_range, rd.apply_dmask = True, True, True\n","    rd.preprocess_image()\n","\n","    ax[1,0].imshow(rd.im_bwarped, cmap = 'gray')\n","\n","    # run sliding window\n","    rd.run_window_search(dev_mode = True)\n","\n","    ax[1,1].imshow(rd.im_win)\n","\n","    rd.validate_lane_update(dev_mode = True)\n","    rd.get_dynamic_mask()\n","\n","    rd.polyfit_search(dev_mode = True)\n","\n","    if rd.road_det:\n","      ax[1,2].imshow(rd.im_polyfit)\n","\n","  for axes in ax.flatten() :\n","      axes.axis('off')\n","  plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1SXqExuLm-x14AEaXPd804UzLAYMN43vG"},"id":"cbGrwGOj_WLU","outputId":"842d3349-fbe8-4698-b11c-32c0df664488","executionInfo":{"status":"ok","timestamp":1668616873145,"user_tz":-60,"elapsed":22199,"user":{"displayName":"W. Engel","userId":"14312250423475286177"}}},"id":"cbGrwGOj_WLU","execution_count":194,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"tf25","language":"python","name":"tf25"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"colab":{"provenance":[],"collapsed_sections":["g5HVluC8GegD","_IduVxxNHDYc","xj8Ewq7SJqyd","2c002ba0","03352666","9aoPOwg89fIA","DvVizpCm9xkG","VpzbVdSM97n_","4f88e113","mPZ8HqAB2Y7e","jWKffIcf2ibz","O1uF6mp5iC0R","a3e8c6b9","7Mojo7eywZOp","0ZhTzVKRIE0k","3tiw1Vx-IBR9"]}},"nbformat":4,"nbformat_minor":5}